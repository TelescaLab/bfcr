\documentclass[useAMS,referee,usenatbib]{biom}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\DeclareMathOperator{\E}{\mathbb{E}}
\newcommand{\vect}{\text{vec}}
\title[This is an Example of Recto Running Head]{Bayesian Functional Covariance Regression}

%  Here are examples of different configurations of author/affiliation
%  displays.  According to the Biometrics style, in some instances,
%  the convention is to have superscript *, **, etc footnotes to indicate 
%  which of multiple email addresses belong to which author.  In this case,
%  use the \email{ } command to produce the emails in the display.

%  In other cases, such as a single author or two authors from 
%  different institutions, there should be no footnoting.  Here, use
%  the \emailx{ } command instead. 

%  The examples below corrspond to almost every possible configuration
%  of authors and may be used as a guide.  For other configurations, consult
%  a recent issue of the the journal.

%  Single author -- USE \emailx{ } here so that no asterisk footnoting
%  for the email address will be produced.

%\author{John Author\emailx{email@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Two authors from the same institution, with both emails -- use
%  \email{ } here to produce the asterisk footnoting for each email address

%\author{John Author$^{*}$\email{author@address.edu} and
%Kathy Authoress$^{**}$\email{email2@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Exactly two authors from different institutions, with both emails  
%  USE \emailx{ } here so that no asterisk footnoting for the email address
%  is produced.

\author{John Shamshoian$^{1}$\email{donatello.telesca@ucla.edu}, Damla {\c S}ent{\"u}rk$^{1}$, Shafali Jeste$^{2}$, and Donatello Telesca$^{1,*}$ \\$^{1}$Department of Biostatistics, University of California, Los Angeles, California 90095, U.S.A.\\$^{2}$ Department of Psychiatry and Biobehavioral Sciences, University of California, Los Angeles,\\ California 90095, U.S.A.}
\title[Bayesian Functional Covariance Regression]{Bayesian Functional Covariance Regression}


\begin{document}


\label{firstpage}

%  put the summary for your paper here

\begin{abstract}
	Many electroencephalography (EEG) studies aim to compare cognitive function between and within diagnostic groups. In our motivating study, resting state EEG data is collected on in a sample of 59 children with autism spectrum disorder and 38 age-matched typically developing (TD) controls. Peak alpha frequency (PAF), the frequency of maximal power within the alpha range (6 - 14 Hz), is a biomarker related to cognitive development and is known to increase with age in TD children. In this article we model alpha spectral power, rather than just the peak location. Patterns of variability of alpha spectral power between children are obscured by factors such as age. In the present work we develop methodology to estimate covariate-adjusted dependency patterns of alpha band oscillations, allowing for valid group level inference.  
\end{abstract}

%  Please place your key words in alphabetical order, separated
%  by semicolons, with the first letter of the first word capitalized,
%  and a period at the end of the list.
%

\begin{keywords}
	Autism spectrum disorder; Covariance regression; Functional data analysis; Peak alpha frequency; Power spectral density; Sleep heart health study.
\end{keywords}

%  As usual, the \maketitle command creates the title and author/affiliations
%  display 

\maketitle


\section{Introduction}
\label{s:intro}
Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder that affects about 1 in 54 children. ASD is characterized by difficulty in communication, restricted repetitive behaviors, and stereotypical behavior. Low functioning children may have limited behavioral repertoire, necessitating specialized assessment methods. Electroencephalography (EEG) provides a direct measure of postsynaptic brain activity and does not rely on behavioral output from young children with ASD, making EEG based biomarkers appealling for diagnosis, prognosis, and intervention purposes \citep*{Jeste2015}. In this article's motivating study, 59 heterogenous children with ASD and 38 age matched typically developing (TD) children had resting-state EEG signals recorded \citep*{Dickinson2017}. This study focused on alpha waves, which play a role in neural coordination and communication between distributed brain regions.

The study investigated investigated peak alpha frequency (PAF), the frequency at which oscillations in the alpha rhythm [6-14 Hz] achieve maximal power and is known to shift from lower to higher frequencies as TD children age. The study found that children with ASD did not show increasing PAF with age. Furthermore, PAF was strongly correlated with non-verbal cognition. In this article we take a broader view and investigate the entire alpha spectrum as opposed to collapsing this information to a single point. EEG signals were recorded using a 128-channel sensor net at 500 Hz. After post-processing the raw EEG data, each child has 25 regions of interest and alpha spectral power captured from 6 to 14 Hz with .25 Hz increments. We propose to treat this data within a functional data framework, whree each spectral power curve is considered one observation. See \cite{Wang2016} for a broad review on functional data analysis (FDA). 

FDA is a mature body of literature designed to handle high dimensional data with smoothness assumptions. Much attention has been devoted to estimating conditional means in a mixed model framework \citep{Guo2002, Morris2006, Montagna2012}. Less studied is the problem of estimating conditional patterns of variability. \cite{Cardot2007} developed a method to extract conditional patterns of variability for dense functional data and \cite{Jiang2010} extended this procedure to accommodate sparse functional data. These methods lie in the Frequentist framework and rely on bootstrap to perform uncertainty quantification. In addition, both methods do not scale appropriately for more than one covariate or group indicators. We propose a Bayesian covariate-adjusted FPCA model to estimate conditional patterns of variability of alpha spectral power, conditional on age and diagnostic status. Posterior sampling defines a straightforward mechanism for completing inference at the cost of specifying priors on all unknown parameters. The proposed method can accommodate group indicators or several variables due to some linearity assumptions. 

The proposed method is closely related to the notion of regularized covariance estimation. As an early reference for regularized covariance estimation, \citet{Flury1984} developed a method to estimate a common set of principal components across $k$ groups. This concept was generalized by \citet{Franks2019}, who use partial pooling to estimate a set of principal components across $k$ groups. \citet{Fox2015} developed a Bayesian nonparametric method for estimating a time-varying covariance matrix through factor matrix products, where the loading of the factor matrix depending on predictors. However it's unclear how to extend this method in the context of independent functional observations or include discrete covariates such as group indicators. In contrast, \citet{Hoff2012} extends to allow factor loading to depend on continuous or discrete covariates. However, this flexibility requires some linear assumptions, which is in spirit similar to linear regression. See \citet{Li2014} and \citet{Quintero2017} for extensions of this model to the multivariate multilevel case. The model presented in Section \ref{s:model} can be seen as a functional extension of \citet{Hoff2012}, and we will highlight the similarities and differences as we go along. 

The rest of this paper is organized as follows: Section \ref{s:model} gives the generating model for functional data, Section \ref{s:priors} lists prior choices and discusses the reasoning behind them, section \ref{s:posteriors} focuses on inference such as credible intervals for mean functions, Section \ref{s:simulation} gives a thorough simulation study, Section \ref{s:data} showcases the model on the motivating EEG case study, and Section \ref{s:discussion} concludes with a brief discussion. The sampling algorithm and  simulation study information are given in the supplement.

\section{Model}
\label{s:model}
In this section we present the model associating patterns of variability and time-stable covariates. Let $y_{i}(t)$ denote the outcome for subject $i$ at point $t \in \mathcal{T}$ for some real compact interval $\mathcal{T}$. Let $\bmath{x} = (x_{1},\ldots,x_{d_{1}})^{\top}$ denote a $d_{1}$-dimensional time-stable covariate for subject $i$, with the dependence on $i$ removed for ease of presentation. The $k$-dimensional data-generating model is 
\begin{gather}
y_{i}(t) = \mu(t, \bmath{x})   + r_{i}(t, \bmath{x})  + \epsilon_{i}(t)\label{eq:model}\\
r_{i}(t, \bmath{x}) = \sum_{j=1}^{k}\psi_{j}(t, \bmath{x})\eta_{ij}\label{eq:covariance}\\
\eta_{ij} \sim N(0, 1),\;\;\;\;\epsilon_{i}(t) \sim N(0, \varphi^{2})
\label{eq:random}
\end{gather}
where $\mu(t, \bmath{x})$ is the conditional mean, $\psi_{j}(t, \bmath{x})$ form conditional latent functional bases, $\eta_{ij} \sim N(0,1)$ are subject-specific scores, and $\epsilon_{i}(t) \sim N(0, \varphi^{2})$ represents measurement error. Using equations (\ref{eq:model}, \ref{eq:covariance}, \ref{eq:random}) the conditional covariance function $c(t, t', \bmath{x})$ is
\begin{gather}
c(t,t', \bmath{x}) = \sum_{j=1}^{k}\psi_{j}(t,\bmath{x})\psi_{j}(t',\bmath{x})\label{eq:covariance_form}
\end{gather}

Specifying the form of $\mu(\cdot)$ and $\psi_{j}(\cdot)$ is a contentious topic and various approaches can be found in the literature including local polynomial smoothers \citep{Fan1996}, kernel smoothers \citep{Ferraty2006}, Gaussian process methods \citep{Yang2016, Fox2015}, and spline procedures \citep{Ramsay2005}. Each method has its own merit and we will compare our developments to some existing approaches in the context of covariance regression. Lending toward conceptually straight-forward prior specifications, we  build $\mu(\cdot)$ and $\psi_{j}(\cdot)$ as linear combinations of spline bases. Borrowing notation from \citet{Scheipl2015}, $\mu(t, \bmath{x})$ can be written as
\begin{gather}
\mu(t, \bmath{x}) = \sum_{r=1}^{R}f_{r}(t, \bmath{x}_{r})
\end{gather}
where the set $\cup\{\bmath{x}_{r}\}_{r=1}^{R} = \mathbf{x}$. This grouping framework leads to flexible specification of basis expansions. For example, when $\bmath{x}_{r}$ is a single scalar covariate $f_{r}(t, x_{r})$ could be a functional linear effect $x_{r}f(t)$ or a smooth effect $f(t, x_{r})$. If $\bmath{x}_{r} = (x_{r_{1}}, x_{r_{2}})$ is a vector of covariates, $f_{r}(t, \bmath{x}_{r})$ could be written as $f_{r}(t, x_{r_{1}}, x_{r_{2}}) = f(t, x_{r_{1}}, x_{r_{2}}), x_{r_{1}}f(t, x_{r_{2}})$, or $x_{r_{1}}x_{r_{2}}f(t)$. These terms are approximated by a set of basis functions with corresponding priors to encourage smooth effects. 

The $f_{r}(t, \bmath{x}_{r})$ terms can be represented by products of matrices and vectors. For example, let $\sum_{j=1}^{p}\sum_{m=1}^{p_{r}}b_{j}(t)b^{r}_{m}(x_{r})  \beta_{rjm}$ be a tensor spline expansion for $f(t, x_{r})$ where $\{b_{j}\}_{j=1}^{p}$ is a marginal basis expansion in $t$ and $\{b_{m}^{r}\}_{m=1}^{p_{r}}$ is a marginal basis expansion in $x_{r}$. Let $\bmath{b}(t) = (b_{1}(t), \ldots, b_{p}(t))^{\top}$, $\bmath{b}^{r}(x_{r}) = (b_{1}^{r}(x_{r}), \ldots, b_{p_{r}}^{r}(x_{r}))^{\top}$, and arrange the coefficients into a $p\times p_{r}$ matrix $\beta_{r}$. For the general case, we maintain that $\bmath{x}_{r}$ could be a vector with basis $\bmath{b}^{r}(\bmath{x}_{r}) = (b_{1}^{r}(\bmath{x}_{r}), \ldots, b_{p_{r}}^{r}(\bmath{x}_{r}))$. Then 
\begin{align}
f_{r}(t, x_{r}) &= \bmath{b}(t)^{\top}\beta_{r} \,\bmath{b}^{r}(\bmath{x}_{r})\label{eq:mu1}\\
\mu(t, \bmath{x}) &= \bmath{b}(t)^{\top} \beta \, \tilde{\bmath{X}}(\bmath{x})\label{eq:mu2}
\end{align}
where $\beta = \big(\beta_{1}\,|\cdots|\,\beta_{R}\big)$ and $\bmath{\tilde{X}}(\bmath{x}) = \big(\bmath{b}^{1}(\bmath{x}_{r})\,|\cdots|\,\bmath{b}^{R}(\bmath{x}_{r})\big)^{\top}$. Keeping track of dimensions,  $\beta$ is a $p\times r(d_{1})$ coefficient matrix and  $\bmath{\tilde{X}}(\bmath{x})$ is a $r(d_{1})\times 1$ vector, where $r(d_{1}) = \sum_{r=1}^{R}p_{r}$. We place another additive model on $\psi_{j}(t, \bmath{x})$. Namely, 
\begin{gather}\psi_{j}(t,\bmath{x}) = \sum_{r=1}^{R}l_{jr}(t,\bmath{x}_{r})\label{eq:psi_additivity}
\end{gather} where $l_{jr}$ are smooth effects in terms of $\bmath{x}_{r}$ for the $j$th conditional latent function basis function. Similar to $f_{r}(t,\bmath{x}_{r})$ and $\mu(t, \bmath{x})$, $l_{jr}(t, \bmath{x}_{r})$ and $\psi_{j}(t, \bmath{x})$ can also be written as products of matrices and vectors:
\begin{align*}
l_{jr}(t, x_{r}) &= \bmath{b}(t)^{\top}\Lambda_{jr}{r} \,\bmath{b}^{r}(\bmath{x}_{r})\\
\psi_{j}(t, \bmath{x}) &= \bmath{b}(t)^{\top}\,\Lambda_{j}\, \bmath{\tilde{X}}(\bmath{x})
\end{align*} where $\Lambda_{jr}$ is a $p\times p_{r}$ loading matrix and  $\Lambda_{j} = \big(\Lambda_{j1}\,|\cdots|\,\Lambda_{jR}\big)$. The additivity on $\psi_{j}(t, \bmath{x})$ implies that the covariance function \ref{eq:covariance_form} is 
\begin{gather*}
c(t, t', \bmath{x}) = \sum_{j=1}^{k}\bigg(\sum_{r=1}^{R}\sum_{r'=1}^{R}l_{jr}(t,\bmath{x}_{r})l_{jr'}(t',\bmath{x}_{r'})\bigg)
\end{gather*} 
This convolution structure makes it difficult to define low dimensional summaries of covariate influence on the covariance function. Instead, we propose a low dimensional summary which quantifies the impact of a covariate on the  $l_{jr}$ functions directly. Let
\begin{equation}
g_{r}(t, \bmath{x}_{r}) = \sum_{j=1}^{k}l_{jr}(t,\bmath{x}_{r})^{2} \label{eq:low}
\end{equation}
summarize the effect of $\bmath{x}_{r}$ across $\psi_{j}$, $j=1,\ldots,k$. If the impact of $\bmath{x}_{r}$ on $\psi_{j}$, $j=1,\ldots,k$ is negligable, then $g_{r}(t, \bmath{x}_{r})$ will be near zero. Consequently if $g_{r}(t, \bmath{x}_{r})$ is near zero, the $c(t,t', \bmath{x})$ will not be sensitive to changes in $\bmath{x}_{r}$. To the best of our knowledge, this is the first attempt at quantifying the impact of covariates on a covariance function which is only possible through the additivity assumption on $\psi_{j}(t, \bmath{x})$ from equation \ref{eq:psi_additivity}.

Unlike previous work on functional covariance regression \citep{Cardot2007, Jiang2010}, equations (\ref{eq:model}, \ref{eq:covariance}, \ref{eq:random}) specify a generative model for functional covariance regression. Complete with priors detailed in Section \ref{s:priors}, posterior inference is evaluated through Markov-Chain Monte Carlo (MCMC). This is important because empirical methods require resampling to perform inference. However, resampling techniques for functional data come with pitfalls. Any fitted model will have smoothing bias (to regularize rapidly varying functions). A parametric bootstrap would generate data from a biased model, and subsequently cause even more bias by smoothing once again for each bootstrap replicate. Nonparametric bootstrapping causes undersmoothing due to the presence of repeated functions.

Outside of the FDA literature, \citet{Hoff2012} developed a similar model for covariance regression with multivariate data. However, as \citet{Fox2015} note, their mapping from predictors to covariance assumes a parametric form, thus limiting the model's expressivity. To overcome this parametric limitation, the authors develop a factor matrix process estimate a time-varying covariance matrix characterizing influenza incidence across the United States. This approach is flexible but each gibbs sample iteration requires a cholesky decomposition of an $n\times n$ matrix where $n$ is the number of subjects. The basis transform approach taken here would only require a cholesky decomposition of a $p \cdot r(d_{1}) \times p\cdot r(d_{1})$ matrix for each iteration. Therefore the basis transform approach is likely to scale better for large data sets such as the SHHS, provided $r(d_{1})$ is not too large.  
\section{Prior Distributions}
\label{s:priors}
In this section we place priors on all unknown quantities of interest. We begin by placing prior on $\mu(t, \bmath{x})$. As we have seen in equations \ref{eq:mu1} and \ref{eq:mu2}, this amounts to placing a prior on each $\beta_{r}$ submatrix. The rows of $\beta_{r}$ are associated with a $p\times p$ penalty matrix $K$, and the columns of $\beta_{r}$ are associated with a $p_{r}\times p_{r}$ penalty matrix $K_{r}$. These penalties are designed to encourage smoothness and can target magnitude penalization, squared derivative shrinkage, or local changes in $\beta_{r}$ through a differencing penalty. In this paper we penalize the second order difference of $\beta_{r}$ coefficients in both directions, but other penalties could be used as well. A prior for $\beta_{r}$ respecting the tensor structure is constructed as follows \citep{Wood2017}. Let $\tilde{K} = I_{p_{r}\times p_{r}}\otimes K$ and $\tilde{K_{r}} = K_{r} \otimes I_{p\times p}$. The prior for the vectorized form of $\beta_{r}$ is

\begin{gather*}
\vect(\beta_{r}) \,|\, \tau_{1xr}, \tau_{1tr} \sim\\ \exp\{-0.5\vect(\beta_{r})^{\top}( \tau_{1xr} \tilde{K}_{r} + \tau_{1tr}\tilde{K})\vect(\beta_{r})\}
\end{gather*} 
where $\tau_{1xr}, \tau_{1tr}$ are smoothing parameters. If $p_{r} = 1$ then $\beta_{r}$ is a $p\times 1$ vector and $\tilde{K}_{r} = 0$. In this case the prior simplifies to 
\begin{align*}
\beta_{r} \,|\tau_{1tr}\sim \exp\{-0.5\tau_{1tr}\beta_{r}^{\top}\tilde{K}\beta_{r}\}
\end{align*}
This prior is improper but provided that proper priors are set for $\tau_{1tr}, \tau_{1xr}$, the posterior of $\beta_{r}$ will be proper \citep{Lang2004}. Priors for $\psi_{j}(t, \bmath{x})$. However, $\psi_{j}(t,\bmath{x})$ for larger $j$ should also contribute less to the fit than earlier terms. Therefore the prior for $\psi_{j}(t,\bmath{x})$ should encourage smoothing and shrinkage aspects. Let $\Lambda_{rj}$ be the analogous component to $\beta_{r}$. Re-using the same penalty matrices as above, the prior for $\Lambda_{rj}$ is 
\begin{gather*}
\vect(\Lambda_{rj})\,|\,\tau_{2jxr},\tau_{2jtr}, \tau_{rj}^{*}, \phi_{rj} \sim \\\exp \{-0.5\vect(\Lambda_{rj})^{\top}(\tau_{2jxr}\tilde{K}_{r} + \tau_{2jtr}\tilde{K} + \tau^{*}_{rj}\phi_{rj})\vect(\Lambda_{rj})\}
\end{gather*}
where $\tau_{2jxr}, \tau_{2jtr}$ are smoothing parameters and $\phi_{rj}$, $\tau^{*}_{rj}$ are shrinkage parameters. Here $\phi_{rj}$ is a diagonal matrix with dimension $p\cdot p_{r}\times p\cdot p_{r}$. If $p_{r} =1$ (so that $\Lambda_{rj}$ is a column vector), then the prior becomes
\begin{gather*}
\Lambda_{rj} \,|\tau_{2jtr}, \tau^{*}_{rj},\phi_{rj} \sim\\
\exp\{-0.5\Lambda_{rj}^{\top}(\tau_{2jtr}\tilde{K} + \phi_{rj}\tau^{*}_{rj})\Lambda_{rj}\}
\end{gather*}
similar to the case when $\beta_{rj}$ is a column vector. In summary, these priors for $\mu(t,\bmath{x})$ and $\psi_{j}(t,\bmath{x})$ are design to reflect our assumptions of smoothness in the functional data outcomes. All smoothing parameters are given a gamma prior distribution, 
\begin{gather*}
\tau_{1xr}, \tau_{1tr} \sim \text{Gamma}(a_{\tau}, b_{\tau})\\
\tau_{2jxr}, \tau_{2jtr} \sim \text{Gamma}(a_{\tau}, b_{\tau})
\end{gather*}
where we use the `rate' parameterization of the Gamma distribution (i.e., if $x \sim Gamma(a, b)$, then $\E[x] = a/b$). In addition we use ideas from the Gamma Multiplicative Process Prior (GMPP) \citep{Bhattacharya2011, Montagna2012} to assign priors to $\tau^{*}_{rj}$ and $\phi_{rj}$. The prior for $\tau^{*}_{rj}$ is
\begin{align*}
\tau^{*}_{rj} &= \prod_{l=1}^{r}\delta_{lr}\\
\delta_{r1} &\sim \text{Gamma}(a_{r0}, 1)\\
 \delta_{rl} &\sim \text{Gamma}(a_{r1}, 1),\,\, l > 1\\
 a_{r0}, a_{r1} &\sim \text{Gamma}(2,1)
\end{align*}
so that the $\tau_{rj}$ are stochastically increasing in $j$. This shrinkage is data-adaptive so that later entries of $\Lambda_{rj}$ may or may not be shrunk toward zero depending on the model fit. In particular, specifying a conservative choice of $k$ (number of latent functional factors) should not change results too much compared to setting $k$ to some ``optimal'' choice. 

\section{Simulations}
\subsection{Markov-Chain Monte-Carlo and Posterior Distributions}
\label{s:posteriors}
Analytic posterior distributions are intractable, so we rely on Markov-Chain Monte-Carlo techniques to draw samples from all relevant posterior distributions. Since all full conditionals of blocks of parameters are available in closed form, a simple Gibbs sampler updates each parameter block sequentially. See Web Appendix A for all block parameter updating steps.

When the target of inference is a function $f$, as opposed to a single point, we adopt methodology from \citet{Crainiceanu2007} to form simultaneous credible bands. Suppose the domain of $f$ is $[t_{1}, t_{N}]$ and let $t_{1} < \ldots < t_{N}$ be a fine grid of points on this interval. Let $\mathbb{E}\{f(t_{j})\}$ and $\text{SD}\{f(t_{j})\}$ be the pointwise posterior mean and standard deviation of $f(t_{j})$ respectively. Let $\alpha^{*}$ be the $(1-\alpha)$ sample quantile of $\max_{1\leq j \leq N} |f(t_{j}) - \mathbb{E}\{f(t_{j})\}|/\text{SD}\{f(t_{j})\}$. Then $\mathbb{E}\{f(t_{j})\} \pm \alpha^{*} \text{SD}\{f(t_{j})\}, 1\leq j\leq N$ constitute $(1-\alpha)$ simultaneous credible intervals. This simultaneous credible band will be used to evaluate uncertainty in the mean and aspects of the covariance in Section~\ref{s:data}.

\section{Operative Characteristics}
\label{s:simulation}

Please see the file \texttt{biomsample.tex} for fancy examples of making
tables.  Here is a very simple one.  Use \texttt{table} for tables
that are narrow enough to fit in one column of the typeset journl; use
\texttt{table*} for tables that need to span two columns.  For
figures, use of \texttt{figure} and \texttt{figure*} is analogous. 



\section{Case Studies}
\subsection{Application to ASD study}
Peak alpha frequency (PAF), the frequency at which oscillations in the alpha range demonstrate maximal power, shows well-characterised increases with chronological age during childhood in typically developing children \citep{Somsen1997, Dustman1999, Stroganova1999, Chiang2011, Cragg2011, Miskovic2015}. PAF has been shown to index neural development in TD children \citep{Valdes2010, Segalowitz2010, Rodriguez2017}. However, a recent study by \citet{Dickinson2017} found that children with ASD did not show the typical increase in PAF with age. In the present study, we investigate the relationship between diagnostic status, age, and alpha spectral density. Treating alpha spectral density as a functional response avoids complicated PAF identification procedures \citet{Dickinson2017} and retains more information as opposed to collapsing the entire alpha spectral band to a single point \citep{Scheffler2019, Scheffler2020}. In this study we wish to characterize functional mean and covariance dependence of alpha spectral density in terms of age and diagnostic status. 

In the \citet{Dickinson2017} study, resting-state EEG was collected on 39 TD children and 58 children with ASD aged 2 to 12 years old.  EEG signals were sampled at 500 Hz for two minutes and interpolated to a 10-20 25 channel montage \citep{Jasper1958, Perrin1989}. Alpha spectral density  $\Omega \in [6 \text{ Hz}, 14 \text{ Hz}]$ were obtained for each electrode. To facilitate comparisons across regions and subjects, alpha spectral density was normalized to unit area. See \cite{Scheffler2019} for more details on data acquisition and pre-processing. The resulting data structure is region-referenced functional data, which induces correlated responses within subjects. Unfortunately, the proposed method can not accommodate correlated functional data. Instead, for demonstration purposes, we only examine one region at a time. We also acknowledge that \citet{Scheffler2020} already successfully applied a covariate-adjusted hybrid principal components analysis, which can accommodate correlated functional responses within subject. While the goals of \citet{Scheffler2020} are similar to the ones posed in this article, we note that this method is (1) based on a Bayesian method, which yields stochastic regularization and straight-forward inference and (2) the low dimensional summary in eq. \ref{eq:low} provides some insight into how the variability of normalized alpha spectral density as a function of age and diagnostic status. 

We treat normalized alpha spectral density from the T8 region as the functional response and adjust the mean and covariance functions by diagnostic status, age, and a diagnostic status by age interaction. This interaction is scientifically motivated because as previously mentioned, PAF increases with age for TD children but not so for children with ASD. For the frequency dimension, we use a p-spline basis with 12 degrees of freedom using a second order differencing penalty. We expand age via p-splines with 6 degrees of freedom, again with a second order difference penalty. We run a markov chain monte carlo algorithm for 200,000 iterations. To save on memory purposes, we only save every 20 iterations. Of the leftover 10,000 iterations, we discard the first 5,000 as burn-in and keep the subsequent 5,000 for inference.  

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/Peak Alpha Data/Graphics/means.png}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width = .8\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/Peak Alpha Data/Graphics/eigen1.png}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width = .6\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/Peak Alpha Data/Graphics/covariate_effects_parsed.pdf}
\end{figure}

\subsection{Application to Sleep Heart Health Study}
The Sleep Heart Health Study (SHHS) was a prospective cohort study designed to investigate obstructive sleep apnea (OSA) and other sleep-disordered breathing (SDB) as risk factors for the development of cardiovascular disease \citep{Quan1997}. Parent cohort studies and recruitment targets for these cohorts are the following: Atherosclerosis Risk in Communities Study (1,750 participants), Cardiovascular Health Study (1,350 participants), Framingham Heart Study (1,000 participants), Strong Heart Study (600 participants), New York Hy- pertension Cohorts (1,000 participants), and Tucson Epidemiologic Study of Airways Obstructive Diseases and the Health and Environment Study (900 participants). An unattended in-home polysomnography was completed by participants between November 1, 1995 and January 31, 1998. Between January 2001 and June 2003, a second polysomnogram was obtained in 3295 of the participants. %The baseline SHHS cohort included 52.9\% women and 47.1\% men. The race distribution was 81\% Caucasians, 9.\% Native-Americans, 8.0\% African-Americans, 1.3\% Asians, and 0.03\% `other' race category. The minimum age of enrollment was 40 years and there was no upper limit. The mean age was 62.9 (SD 11.0) years old. 

The American Academy of Sleep recognizes four sleep stages: stage N1 (light sleep), stage N2 (relaxation), stage N3 (slow-wave sleep), and stage R (rapid-eye movement). Importantly, N3 sleep, or slow-wave sleep (SWS) consists of high amplitude ($\geq$ 75 $\mu$V) and low-frequency  $(0.5-4.0)$ delta waves. SWS is considered to be most restorative sleep stage and to be associated with sleep quality, sleep maintenance, and functions toward memory consolidation \citep{Bonnet1987, Akerstedt1997, Walker2009}. \citet{Mander2017} reports that advancing into the fifth decade of age comes with (1) reduced SWS time and (2) increased time spent in lighter sleep stages (N1, N2). In addition, \citet{Javaheri2018} reports that lower levels of percent SWS sleep are associated with increased odds of incident hypertension in both men and women, independent of confounders such as sleep apnea, age, and sex. Most clinical studies (including the papers referenced above) quantify sleep by classifying time-varying electrical phenoma into discrete sleep stages. Subsequently, amount of SWS is represented by a single number, which is commonly percentage of sleep time in stage N3. However, this approach comes with several limitations \citep{Crainiceanu2009} including low intraclass correlation coefficient, no biological basis, and loss of temporal information. In this paper follow \citet{Crainiceanu2009, Di2009} and use power spectral density analysis to quantify sleep EEG. Our present goal is to characterize age-related changes in sleep between hypertension and non-hypertension groups. 

We use the discrete fast Fourier transform to analyze the sleep EEG data in the frequency domain. The entire night of sleep is broken into 30-second adjacent sleep epochs to account for temporal effects. These 30-second windows are processed using Welch's method of 50\% overlapping windows (4 second windows with 2 seconds overlap), where the intervals are windowed using a tapered Tukey window. The epoch-level power spectral density estimate is the average of the windowed power spectra. We use a band-pass filter to attenuate signals less than .3 Hz and greater than 35 Hz with a .5 Hz transition width. We mask epochs where artifacts detected using the method described in \citet{Buckelmuller2006}. We also mask epochs that are statistical outliers using (2, 2) Hjorth parameters \citet{Hjorth1970}. We compute delta spectral power by summing power spectra from 0.5 Hz to 4.0 Hz in .25 Hz increments on an epoch-by-epoch basis. To facilitate comparisons across participants, we compute epoch-level relative delta power spectral density by dividing this power density by a summation of spectral density from .5 Hz to 35 Hz in .25 Hz increments. All filtering and power spectral density computations were performed in Luna \citep{Shaun2020}, which is an open-source software package for manipulating and analyzing polysomnographic readings.

We restrict our attention to EEG data collected on the first visit. We also filter participants to only include those who scored at least four hours of artifact-free signal. We analyze the first two hours of sleep, resulting in a dense grid of length 240 epochs for each participant. The 10th and 90th percentiles of age are 47 and 77 years-old, respectively. There are 2177 participants with hypertension and 3081 participants without hypertension.
% eeg details, question setup, mcmc control, spline setup

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/sleep/Graphics/means.pdf}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width = .8\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/sleep/Graphics/eigen1.png}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width = .6\textwidth]{/Users/johnshamshoian/Documents/R_projects/bfcr/sleep/Graphics/covariate_effects_parsed.pdf}
\end{figure}
 Of interest is the C3/A2 EEG channel sampled at 125 Hz. Sleep scoring is usually a visually-based counting process, where every 30-second epoch of sleep is assigned a discrete stage
\label{s:data}

\section{Discussion}
\label{s:discussion}

You can experiment with fancier tables than Table~\ref{t:one}.

We can get bold symbols using \verb+\bmath+, for example, $\bmath{\alpha}_i$.


Put your final comments here. 

%  The \backmatter command formats the subsequent headings so that they
%  are in the journal style.  Please keep this command in your document
%  in this position, right after the final section of the main part of 
%  the paper and right before the Acknowledgements, Supporting Information (Supplementary %  Materials),   and References sections. 

\backmatter

%  This section is optional.  Here is where you will want to cite
%  grants, people who helped with the paper, etc.  But keep it short!

\section*{Acknowledgements}

The authors thank Professor A. Sen for some helpful suggestions,
Dr C. R. Rangarajan for a critical reading of the original version of the
paper, and an anonymous referee for very useful comments that improved
the presentation of the paper.\vspace*{-8pt}



%  Here, we create the bibliographic entries manually, following the
%  journal style.  If you use this method or use natbib, PLEASE PAY
%  CAREFUL ATTENTION TO THE BIBLIOGRAPHIC STYLE IN A RECENT ISSUE OF
%  THE JOURNAL AND FOLLOW IT!  Failure to follow stylistic conventions
%  just lengthens the time spend copyediting your paper and hence its
%  position in the publication queue should it be accepted.

%  We greatly prefer that you incorporate the references for your
%  article into the body of the article as we have done here 
%  (you can use natbib or not as you choose) than use BiBTeX,
%  so that your article is self-contained in one file.
%  If you do use BiBTeX, please use the .bst file that comes with 
%  the distribution.  In this case, replace the thebibliography
%  environment below by 
%
%  \bibliographystyle{biom} 
% \bibliography{mybibilo.bib}

\bibliographystyle{biom}  \bibliography{mybiblio}



%  If your paper refers to supporting web material, then you MUST
%  include this section!!  See Instructions for Authors at the journal
%  website http://www.biometrics.tibs.org


\section*{Supporting Information}

Web Appendix A, referenced in Section~\ref{s:posteriors}, is available with
this paper at the Biometrics website on Wiley Online
Library.\vspace*{-8pt}

\appendix

%  To get the journal style of heading for an appendix, mimic the following.

\section{}
\subsection{Title of appendix}

Put your short appendix here.  Remember, longer appendices are
possible when presented as Supplementary Web Material.  Please 
review and follow the journal policy for this material, available
under Instructions for Authors at \texttt{http://www.biometrics.tibs.org}.

\label{lastpage}
\end{document}
